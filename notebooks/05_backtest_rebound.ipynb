{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "590f1e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jmbf2\\anaconda3\\envs\\ML\\lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but HistGradientBoostingClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\jmbf2\\anaconda3\\envs\\ML\\lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but HistGradientBoostingClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PDH_prev': {'f1_macro_val': 0.6118868240415203,\n",
       "  'recall_rebound_val': 0.532608695652174,\n",
       "  'params': {'t_event': 0.6, 't_none': 0.55, 't_r': 0.6, 'm_rb': 0.1}},\n",
       " 'PDL_prev': {'f1_macro_val': 0.5346938775510204,\n",
       "  'recall_rebound_val': 0.32432432432432434,\n",
       "  'params': {'t_event': 0.6, 't_none': 0.55, 't_r': 0.6, 'm_rb': 0.1}},\n",
       " 'USA_IBH': {'f1_macro_val': 0.6584305791672116,\n",
       "  'recall_rebound_val': 0.5818181818181818,\n",
       "  'params': {'t_event': 0.6, 't_none': 0.55, 't_r': 0.625, 'm_rb': 0.1}},\n",
       " 'USA_IBL': {'f1_macro_val': 0.6616117307933325,\n",
       "  'recall_rebound_val': 0.6339285714285714,\n",
       "  'params': {'t_event': 0.6, 't_none': 0.55, 't_r': 0.6, 'm_rb': 0.1}},\n",
       " 'VWAP': {'f1_macro_val': 0.5465786711527125,\n",
       "  'recall_rebound_val': 0.39473684210526316,\n",
       "  'params': {'t_event': 0.6, 't_none': 0.55, 't_r': 0.6, 'm_rb': 0.1}},\n",
       " 'POC_D1': {'f1_macro_val': 0.6151702204059298,\n",
       "  'recall_rebound_val': 0.5303030303030303,\n",
       "  'params': {'t_event': 0.6, 't_none': 0.55, 't_r': 0.6, 'm_rb': 0.1}},\n",
       " 'VAH_D1': {'f1_macro_val': 0.6074964639321075,\n",
       "  'recall_rebound_val': 0.48484848484848486,\n",
       "  'params': {'t_event': 0.6, 't_none': 0.55, 't_r': 0.6, 'm_rb': 0.1}},\n",
       " 'VAL_D1': {'f1_macro_val': 0.5816160118606375,\n",
       "  'recall_rebound_val': 0.42528735632183906,\n",
       "  'params': {'t_event': 0.6, 't_none': 0.55, 't_r': 0.6, 'm_rb': 0.1}}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np, pandas as pd, joblib\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# --- Rutas ---\n",
    "DF_PATH   = \"data/interim/ES_5m_2021_2024.parquet\"\n",
    "DATA_PATH = \"data/processed/features/supervised_EUUSA.parquet\"\n",
    "EV_PATH   = \"data/processed/events/events_labeled_2021_2024_EUUSA.parquet\"\n",
    "MODEL     = \"models/artifacts/HGB_EUUSA_f23_calibrated_isotonic.joblib\"\n",
    "\n",
    "# --- Carga base ---\n",
    "df        = pd.read_parquet(DF_PATH)\n",
    "D         = pd.read_parquet(DATA_PATH)     # X + idx + zone_type + target\n",
    "ev_euusa  = pd.read_parquet(EV_PATH)       # idx, zone_type, level_price, side_at_event, label,...\n",
    "\n",
    "# Split temporal (2021-2023 train, 2024H1 val, 2024H2 test)\n",
    "t_series  = df[\"Time\"].dt.tz_convert(\"Europe/Madrid\")\n",
    "idx_ser   = D[\"idx\"].astype(int)\n",
    "TR = (t_series.loc[idx_ser] < \"2024-01-01\").values\n",
    "VA = (t_series.loc[idx_ser] >= \"2024-01-01\").values & (t_series.loc[idx_ser] < \"2024-07-01\").values\n",
    "TE = (t_series.loc[idx_ser] >= \"2024-07-01\").values\n",
    "\n",
    "# Matriz de features X y etiquetas\n",
    "X = D.drop(columns=[\"target\",\"idx\",\"zone_type\"], errors=\"ignore\").copy()\n",
    "num = X.select_dtypes(include=[np.number]).columns\n",
    "X[num] = X[num].fillna(0.0).astype(np.float32)\n",
    "y      = D[\"target\"].astype(str).values\n",
    "zones  = D[\"zone_type\"].astype(str).values\n",
    "idxs   = D[\"idx\"].astype(int).values\n",
    "\n",
    "# Modelo calibrado (isotónica)\n",
    "model   = joblib.load(MODEL)\n",
    "classes = model.classes_\n",
    "\n",
    "# Probabilidades en validación y test\n",
    "Pva, yva, zva, iva = model.predict_proba(X[VA]), y[VA], zones[VA], idxs[VA]\n",
    "Pte, yte, zte, ite = model.predict_proba(X[TE]), y[TE], zones[TE], idxs[TE]\n",
    "\n",
    "def decide_rebound_only(P, classes, t_event, t_none, t_r, m_rb=0.0):\n",
    "    \"\"\"Predicción binaria {'rebound','none'} con gate evento y margen contra breakout.\"\"\"\n",
    "    c2i = {c:i for i,c in enumerate(classes)}\n",
    "    pr, pb, pn = P[:,c2i[\"rebound\"]], P[:,c2i[\"breakout\"]], P[:,c2i[\"none\"]]\n",
    "    event_conf = np.maximum(pr, pb)\n",
    "    yhat = np.where(\n",
    "        (event_conf >= t_event) & (pn <= t_none) & (pr >= t_r) & ((pr - pb) >= m_rb),\n",
    "        \"rebound\", \"none\"\n",
    "    )\n",
    "    return yhat\n",
    "\n",
    "ZONES = [\"PDH_prev\",\"PDL_prev\",\"USA_IBH\",\"USA_IBL\",\"VWAP\",\"POC_D1\",\"VAH_D1\",\"VAL_D1\"]\n",
    "best_by_zone = {}\n",
    "\n",
    "# Requisito: recall mínimo para 'rebound' (p.ej. 20%) para evitar colapsar recall\n",
    "RECALL_MIN = 0.20\n",
    "\n",
    "for z in ZONES:\n",
    "    m = (zva == z)\n",
    "    if m.sum() == 0:\n",
    "        continue\n",
    "    Pz, yz = Pva[m], yva[m]\n",
    "    yz_bin = np.where(yz == \"rebound\", \"rebound\", \"none\")\n",
    "\n",
    "    best = None\n",
    "    for t_event in np.linspace(0.50, 0.75, 6):\n",
    "        for t_none in np.linspace(0.35, 0.55, 5):\n",
    "            for t_r in np.linspace(0.60, 0.80, 9):\n",
    "                for m_rb in (0.00, 0.05, 0.10):\n",
    "                    yhat = decide_rebound_only(Pz, classes, t_event, t_none, t_r, m_rb)\n",
    "                    # métricas por clase en orden ['rebound','none']\n",
    "                    P_,R_,F_,S_ = precision_recall_fscore_support(\n",
    "                        yz_bin, yhat, labels=[\"rebound\",\"none\"], zero_division=0\n",
    "                    )\n",
    "                    f1_macro = float(F_.mean())\n",
    "                    rec_reb  = float(R_[0])\n",
    "                    # aplica restricción de recall y usa f1_macro como objetivo\n",
    "                    if rec_reb >= RECALL_MIN:\n",
    "                        cand = (f1_macro, rec_reb, (t_event,t_none,t_r,m_rb))\n",
    "                        if (best is None) or (cand > best):\n",
    "                            best = cand\n",
    "    # fallback si nada cumple recall_min: coge el mejor f1_macro sin restricción\n",
    "    if best is None:\n",
    "        best = (0.0, 0.0, (0.55, 0.45, 0.65, 0.05))\n",
    "    best_by_zone[z] = {\n",
    "        \"f1_macro_val\": best[0],\n",
    "        \"recall_rebound_val\": best[1],\n",
    "        \"params\": {\n",
    "            \"t_event\": best[2][0], \"t_none\": best[2][1],\n",
    "            \"t_r\": best[2][2],     \"m_rb\":   best[2][3],\n",
    "        }\n",
    "    }\n",
    "\n",
    "best_by_zone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ef70cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST – precision/recall/F1 por clase [rebound, none]\n",
      "precision: [0.653, 0.511]\n",
      "recall   : [0.248, 0.856]\n",
      "F1       : [0.36, 0.64]\n",
      "support  : [990, 908]\n",
      "\n",
      "Matriz de confusión (rows=true, cols=pred) [rebound, none]:\n",
      " [[246 744]\n",
      " [131 777]]\n",
      "\n",
      "Señales emitidas (rebound): 377 de 1898 ejemplos TEST (19.9%). ATR filter = True @ Q40\n",
      "\n",
      "Resumen por zona (TEST):\n",
      "           samples  signals  signal_rate\n",
      "zone_type                               \n",
      "VWAP           432       61        0.141\n",
      "USA_IBH        315       73        0.232\n",
      "USA_IBL        294       66        0.224\n",
      "POC_D1         224       49        0.219\n",
      "PDH_prev       209       37        0.177\n",
      "VAH_D1         200       37        0.185\n",
      "VAL_D1         142       40        0.282\n",
      "PDL_prev        82       14        0.171\n",
      "\n",
      "Guardado: models/artifacts/rebound_thresholds_by_zone.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jmbf2\\anaconda3\\envs\\ML\\lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but HistGradientBoostingClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# === Bloque 2) Evaluación en TEST con umbrales por zona (+ filtro ATR opcional) ===\n",
    "import numpy as np, pandas as pd, joblib\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
    "\n",
    "# --- rutas (ajusta si usas otras) ---\n",
    "DF_PATH   = \"data/interim/ES_5m_2021_2024.parquet\"\n",
    "DATA_PATH = \"data/processed/features/supervised_EUUSA.parquet\"\n",
    "MODEL     = \"models/artifacts/HGB_EUUSA_f23_calibrated_isotonic.joblib\"\n",
    "\n",
    "# --- decide() binario (rebound vs none), mismo que en bloque 1 ---\n",
    "def decide_rebound_only(P, classes, t_event, t_none, t_r, m_rb=0.0):\n",
    "    c2i = {c:i for i,c in enumerate(classes)}\n",
    "    pr, pb, pn = P[:,c2i[\"rebound\"]], P[:,c2i[\"breakout\"]], P[:,c2i[\"none\"]]\n",
    "    event_conf = np.maximum(pr, pb)\n",
    "    return np.where(\n",
    "        (event_conf >= t_event) & (pn <= t_none) & (pr >= t_r) & ((pr - pb) >= m_rb),\n",
    "        \"rebound\", \"none\"\n",
    "    )\n",
    "\n",
    "# --- carga base (si hace falta recomputar Pte/yte/zte/ite/classes) ---\n",
    "need_probs = any(k not in locals() for k in [\"Pte\",\"yte\",\"zte\",\"ite\",\"classes\",\"df\"])\n",
    "if need_probs:\n",
    "    df  = pd.read_parquet(DF_PATH)\n",
    "    D   = pd.read_parquet(DATA_PATH)\n",
    "    t   = df[\"Time\"].dt.tz_convert(\"Europe/Madrid\")\n",
    "    idx = D[\"idx\"].astype(int)\n",
    "    TE  = (t.loc[idx] >= \"2024-07-01\").values\n",
    "\n",
    "    X = D.drop(columns=[\"target\",\"idx\",\"zone_type\"], errors=\"ignore\").copy()\n",
    "    num = X.select_dtypes(include=[np.number]).columns\n",
    "    X[num] = X[num].fillna(0.0).astype(np.float32)\n",
    "\n",
    "    y      = D[\"target\"].astype(str).values\n",
    "    zones  = D[\"zone_type\"].astype(str).values\n",
    "    model  = joblib.load(MODEL)\n",
    "    classes= model.classes_\n",
    "\n",
    "    Pte = model.predict_proba(X[TE])\n",
    "    yte = y[TE]\n",
    "    zte = zones[TE]\n",
    "    ite = D[\"idx\"].astype(int).values[TE]\n",
    "\n",
    "# --- ATR filtro de régimen (opcional) ---\n",
    "use_atr_filter = True\n",
    "atr_q = 0.40      # cuantil recomendado (sube o baja según agresividad)\n",
    "atr_at_idx = df[\"ATR_14\"].loc[ite].to_numpy()\n",
    "atr_thr = np.nanquantile(df[\"ATR_14\"].values, atr_q) if np.isfinite(df[\"ATR_14\"].values).any() else 0.0\n",
    "\n",
    "# --- predicción binaria por zona ---\n",
    "yhat_bin = np.array([\"none\"]*len(ite), dtype=object)\n",
    "\n",
    "for z, conf in best_by_zone.items():\n",
    "    params = conf[\"params\"]\n",
    "    m = (zte == z)\n",
    "    if m.sum() == 0:\n",
    "        continue\n",
    "    yh = decide_rebound_only(Pte[m], classes, params[\"t_event\"], params[\"t_none\"], params[\"t_r\"], params[\"m_rb\"])\n",
    "    if use_atr_filter:\n",
    "        keep = atr_at_idx[m] >= atr_thr\n",
    "        yh = np.where(keep, yh, \"none\")\n",
    "    yhat_bin[m] = yh\n",
    "\n",
    "# --- métricas TEST (rebote vs none) ---\n",
    "ytrue_bin = np.where(yte==\"rebound\",\"rebound\",\"none\")\n",
    "P_,R_,F_,S_ = precision_recall_fscore_support(ytrue_bin, yhat_bin, labels=[\"rebound\",\"none\"], zero_division=0)\n",
    "cm = confusion_matrix(ytrue_bin, yhat_bin, labels=[\"rebound\",\"none\"])\n",
    "\n",
    "print(\"TEST – precision/recall/F1 por clase [rebound, none]\")\n",
    "print(\"precision:\", [round(x,3) for x in P_])\n",
    "print(\"recall   :\", [round(x,3) for x in R_])\n",
    "print(\"F1       :\", [round(x,3) for x in F_])\n",
    "print(\"support  :\", S_.tolist())\n",
    "print(\"\\nMatriz de confusión (rows=true, cols=pred) [rebound, none]:\\n\", cm)\n",
    "\n",
    "# --- cobertura de señales (cuántas 'rebound' lanzamos) ---\n",
    "signals = (yhat_bin == \"rebound\").sum()\n",
    "print(f\"\\nSeñales emitidas (rebound): {signals} de {len(yhat_bin)} ejemplos TEST \"\n",
    "      f\"({signals/len(yhat_bin):.1%}). ATR filter = {use_atr_filter} @ Q{int(atr_q*100)}\")\n",
    "\n",
    "# --- resumen por zona (conteo & tasa de señal) ---\n",
    "by_zone = pd.DataFrame({\"zone_type\": zte, \"ytrue\": ytrue_bin, \"yhat\": yhat_bin})\n",
    "summary_zone = (by_zone.assign(sig = (by_zone[\"yhat\"]==\"rebound\").astype(int))\n",
    "                        .groupby(\"zone_type\")\n",
    "                        .agg(samples=(\"yhat\",\"size\"),\n",
    "                             signals=(\"sig\",\"sum\"))\n",
    "                        .assign(signal_rate=lambda d: d[\"signals\"]/d[\"samples\"])\n",
    "                        .sort_values(\"samples\", ascending=False))\n",
    "print(\"\\nResumen por zona (TEST):\")\n",
    "print(summary_zone.head(10).round(3))\n",
    "\n",
    "# --- guardar umbrales por zona para reproducibilidad ---\n",
    "Path(\"models/artifacts\").mkdir(parents=True, exist_ok=True)\n",
    "pd.DataFrame(best_by_zone).T.to_json(\"models/artifacts/rebound_thresholds_by_zone.json\",\n",
    "                                     orient=\"index\", indent=2)\n",
    "print(\"\\nGuardado: models/artifacts/rebound_thresholds_by_zone.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80dc6427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signals: 377 | Win%: 0.607 | EV (ticks/trade): -0.09\n",
      "Avg win: 6.96 | Avg loss: -10.99\n",
      "\n",
      "Por zona (n, Win%, EV):\n",
      "           count   mean  win_rate\n",
      "zone_type                        \n",
      "USA_IBH       73  1.904     0.699\n",
      "USA_IBL       66  0.197     0.621\n",
      "VWAP          61  0.041     0.607\n",
      "POC_D1        49  0.184     0.633\n",
      "VAL_D1        40 -2.600     0.475\n",
      "PDH_prev      37 -1.595     0.541\n",
      "VAH_D1        37 -0.432     0.595\n",
      "PDL_prev      14 -1.286     0.571\n",
      "\n",
      "Sensibilidad (top 10 por EV):\n",
      "    TP  SL   H    n   Win%  EV_ticks\n",
      "17  16   8  16  377  0.581     0.964\n",
      "15  16   8  10  377  0.570     0.956\n",
      "16  16   8  12  377  0.576     0.892\n",
      "14  16   6  16  377  0.528     0.630\n",
      "12  16   6  10  377  0.520     0.598\n",
      "13  16   6  12  377  0.525     0.593\n",
      "9   12   8  10  377  0.655     0.195\n",
      "11  12   8  16  377  0.658     0.134\n",
      "10  12   8  12  377  0.655     0.110\n",
      "6   12   6  10  377  0.607    -0.062\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd, joblib, json\n",
    "from pathlib import Path\n",
    "\n",
    "# --- rutas ---\n",
    "DF_PATH   = \"data/interim/ES_5m_2021_2024.parquet\"\n",
    "DATA_PATH = \"data/processed/features/supervised_EUUSA.parquet\"\n",
    "MODEL     = \"models/artifacts/HGB_EUUSA_f23_calibrated_isotonic.joblib\"\n",
    "TH_PATH   = \"models/artifacts/rebound_thresholds_by_zone.json\"\n",
    "\n",
    "# --- carga base y split TEST ---\n",
    "df  = pd.read_parquet(DF_PATH)\n",
    "D   = pd.read_parquet(DATA_PATH)\n",
    "t   = df[\"Time\"].dt.tz_convert(\"Europe/Madrid\")\n",
    "idx = D[\"idx\"].astype(int)\n",
    "TE  = (t.loc[idx] >= \"2024-07-01\").values\n",
    "\n",
    "X = D.drop(columns=[\"target\",\"idx\",\"zone_type\"], errors=\"ignore\").copy()\n",
    "num = X.select_dtypes(include=[np.number]).columns\n",
    "X[num] = X[num].fillna(0.0).astype(np.float32)\n",
    "yte  = D[\"target\"].astype(str).values[TE]\n",
    "zte  = D[\"zone_type\"].astype(str).values[TE]\n",
    "ite  = D[\"idx\"].astype(int).values[TE]\n",
    "\n",
    "model   = joblib.load(MODEL)\n",
    "classes = model.classes_\n",
    "# (truco para quitar el warning de sklearn)\n",
    "Pte = model.predict_proba(X[TE].to_numpy())\n",
    "\n",
    "# --- funciones ---\n",
    "def decide_rebound_only(P, classes, t_event, t_none, t_r, m_rb=0.0):\n",
    "    c2i = {c:i for i,c in enumerate(classes)}\n",
    "    pr, pb, pn = P[:,c2i[\"rebound\"]], P[:,c2i[\"breakout\"]], P[:,c2i[\"none\"]]\n",
    "    event_conf = np.maximum(pr, pb)\n",
    "    return np.where(\n",
    "        (event_conf >= t_event) & (pn <= t_none) & (pr >= t_r) & ((pr - pb) >= m_rb),\n",
    "        \"rebound\", \"none\"\n",
    "    )\n",
    "\n",
    "with open(TH_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    best_by_zone = json.load(f)\n",
    "\n",
    "# --- predicción binaria por zona + filtro ATR (igual que bloque 2) ---\n",
    "use_atr_filter = True\n",
    "atr_q = 0.40\n",
    "atr_at_idx = df[\"ATR_14\"].loc[ite].to_numpy()\n",
    "atr_thr = np.nanquantile(df[\"ATR_14\"].values, atr_q) if np.isfinite(df[\"ATR_14\"].values).any() else 0.0\n",
    "\n",
    "yhat_bin = np.array([\"none\"]*len(ite), dtype=object)\n",
    "for z, conf in best_by_zone.items():\n",
    "    p = conf[\"params\"]; m = (zte == z)\n",
    "    if m.sum()==0: continue\n",
    "    yh = decide_rebound_only(Pte[m], classes, p[\"t_event\"], p[\"t_none\"], p[\"t_r\"], p[\"m_rb\"])\n",
    "    if use_atr_filter:\n",
    "        keep = atr_at_idx[m] >= atr_thr\n",
    "        yh = np.where(keep, yh, \"none\")\n",
    "    yhat_bin[m] = yh\n",
    "\n",
    "# --- backtest ---\n",
    "TICK      = 0.25\n",
    "P_INVAL   = 6     # stop por invalidación (ticks)\n",
    "TP_TICKS  = 12    # take profit (ticks)\n",
    "H         = 12    # horizonte máx (barras)\n",
    "\n",
    "# nivel y lado por evento (para calcular TP/SL desde el nivel)\n",
    "ev = pd.read_parquet(\"data/processed/events/events_labeled_2021_2024_EUUSA.parquet\") \\\n",
    "       [[\"idx\",\"zone_type\",\"level_price\",\"side_at_event\"]].drop_duplicates()\n",
    "\n",
    "test_ev = pd.DataFrame({\"idx\": ite, \"zone_type\": zte, \"ytrue\": yte, \"yhat\": yhat_bin}) \\\n",
    "          .merge(ev, on=[\"idx\",\"zone_type\"], how=\"left\")\n",
    "\n",
    "def backtest_rebound(ev_rows, df, tp_ticks=TP_TICKS, p_inval=P_INVAL, H=H, tick=TICK):\n",
    "    hi = df[\"High\"].to_numpy(float); lo = df[\"Low\"].to_numpy(float); op = df[\"Open\"].to_numpy(float)\n",
    "    out = []\n",
    "    for _, r in ev_rows.iterrows():\n",
    "        i = int(r[\"idx\"]); \n",
    "        if i+1 >= len(df): continue\n",
    "        lvl = float(r[\"level_price\"]); side = str(r[\"side_at_event\"])\n",
    "        if side == \"support\":\n",
    "            tp = lvl + tp_ticks*tick; sl = lvl - p_inval*tick; direction=\"long\"\n",
    "        else:\n",
    "            tp = lvl - tp_ticks*tick; sl = lvl + p_inval*tick; direction=\"short\"\n",
    "        entry = float(op[i+1]); outcome=\"timeout\"; exit_px=float(op[min(i+H,len(df)-1)]); pnl_ticks=0.0\n",
    "        for j in range(i+1, min(i+H+1, len(df))):\n",
    "            if direction==\"long\":\n",
    "                if lo[j] <= sl: outcome=\"loss\";  exit_px=sl;  pnl_ticks=(exit_px-entry)/tick; break\n",
    "                if hi[j] >= tp: outcome=\"win\";   exit_px=tp;  pnl_ticks=(exit_px-entry)/tick; break\n",
    "            else:\n",
    "                if hi[j] >= sl:\n",
    "                    outcome = \"loss\"\n",
    "                    exit_px = sl\n",
    "                    pnl_ticks = (entry - exit_px) / tick  # NEGATIVO si SL>entry\n",
    "                    break\n",
    "                if lo[j] <= tp:\n",
    "                    outcome = \"win\"\n",
    "                    exit_px = tp\n",
    "                    pnl_ticks = (entry - exit_px) / tick  # POSITIVO si TP<entry\n",
    "                    break\n",
    "        if outcome == \"timeout\":\n",
    "            pnl_ticks = (exit_px - entry)/tick if direction==\"long\" else (entry - exit_px)/tick\n",
    "\n",
    "        out.append({\"idx\":i,\"zone_type\":r[\"zone_type\"],\"side\":side,\"entry\":entry,\"tp\":tp,\"sl\":sl,\n",
    "                    \"exit\":exit_px,\"outcome\":outcome,\"pnl_ticks\":pnl_ticks})\n",
    "    return pd.DataFrame(out)\n",
    "\n",
    "signals = test_ev[test_ev[\"yhat\"]==\"rebound\"].copy()\n",
    "bt = backtest_rebound(signals, df, tp_ticks=TP_TICKS, p_inval=P_INVAL, H=H, tick=TICK)\n",
    "\n",
    "# KPIs\n",
    "n = len(bt)\n",
    "win_rate = (bt[\"outcome\"]==\"win\").mean() if n else 0.0\n",
    "ev = bt[\"pnl_ticks\"].mean() if n else 0.0\n",
    "avg_win  = bt.loc[bt[\"outcome\"]==\"win\",\"pnl_ticks\"].mean()\n",
    "avg_loss = bt.loc[bt[\"outcome\"]==\"loss\",\"pnl_ticks\"].mean()\n",
    "print(f\"Signals: {n} | Win%: {win_rate:.3f} | EV (ticks/trade): {ev:.2f}\")\n",
    "print(f\"Avg win: {avg_win:.2f} | Avg loss: {avg_loss:.2f}\")\n",
    "\n",
    "print(\"\\nPor zona (n, Win%, EV):\")\n",
    "per_zone = bt.groupby(\"zone_type\")[\"pnl_ticks\"].agg(['count','mean'])\n",
    "per_zone[\"win_rate\"] = bt.groupby(\"zone_type\")[\"outcome\"].apply(lambda s: (s=='win').mean())\n",
    "print(per_zone.sort_values(\"count\", ascending=False).round(3).head(10))\n",
    "\n",
    "# --- sensibilidad rápida TP/SL/H ---\n",
    "grid_tp = [10,12,16]\n",
    "grid_sl = [6,8]\n",
    "grid_h  = [10,12,16]\n",
    "summary = []\n",
    "for tp in grid_tp:\n",
    "    for sl in grid_sl:\n",
    "        for h in grid_h:\n",
    "            tmp = backtest_rebound(signals, df, tp_ticks=tp, p_inval=sl, H=h, tick=TICK)\n",
    "            if len(tmp)==0: \n",
    "                summary.append((tp,sl,h,0,0,0)); continue\n",
    "            wr = (tmp[\"outcome\"]==\"win\").mean()\n",
    "            evg= tmp[\"pnl_ticks\"].mean()\n",
    "            summary.append((tp,sl,h,len(tmp),wr,evg))\n",
    "            \n",
    "sens = pd.DataFrame(summary, columns=[\"TP\",\"SL\",\"H\",\"n\",\"Win%\",\"EV_ticks\"]).sort_values([\"EV_ticks\",\"n\"], ascending=False)\n",
    "print(\"\\nSensibilidad (top 10 por EV):\")\n",
    "print(sens.head(10).round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb7e55d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signals: 323 | Win%: 0.601 | EV (ticks/trade): 7.00\n",
      "           count   mean    win\n",
      "zone_type                     \n",
      "USA_IBH       73  7.685  0.658\n",
      "USA_IBL       66  6.727  0.606\n",
      "VWAP          61  8.109  0.574\n",
      "POC_D1        49  5.612  0.673\n",
      "PDH_prev      37  6.892  0.514\n",
      "VAH_D1        37  6.216  0.514\n",
      "Guardado: experiments/runs/rebound_v01_trades_test.csv, rebound_v01_summary.json\n"
     ]
    }
   ],
   "source": [
    "# === Rebound v0.1 – Backtest con whitelist de zonas y TP/SL/H recomendados ===\n",
    "import json, pandas as pd, numpy as np, joblib\n",
    "from pathlib import Path\n",
    "\n",
    "# rutas y objetos ya conocidos\n",
    "DF_PATH   = \"data/interim/ES_5m_2021_2024.parquet\"\n",
    "DATA_PATH = \"data/processed/features/supervised_EUUSA.parquet\"\n",
    "EV_PATH   = \"data/processed/events/events_labeled_2021_2024_EUUSA.parquet\"\n",
    "MODEL     = \"models/artifacts/HGB_EUUSA_f23_calibrated_isotonic.joblib\"\n",
    "TH_PATH   = \"models/artifacts/rebound_thresholds_by_zone.json\"\n",
    "\n",
    "# params v0.1\n",
    "ZONE_WHITELIST = {\"USA_IBH\",\"USA_IBL\",\"VWAP\",\"POC_D1\",\"PDH_prev\",\"VAH_D1\"}  # excluye VAL_D1/PDL_prev\n",
    "ATR_Q = 0.40\n",
    "TP_TICKS, SL_TICKS, H = 16, 8, 16\n",
    "TICK = 0.25\n",
    "\n",
    "# carga base y split TEST\n",
    "df  = pd.read_parquet(DF_PATH)\n",
    "D   = pd.read_parquet(DATA_PATH)\n",
    "t   = df[\"Time\"].dt.tz_convert(\"Europe/Madrid\")\n",
    "idx = D[\"idx\"].astype(int)\n",
    "TE  = (t.loc[idx] >= \"2024-07-01\").values\n",
    "\n",
    "X = D.drop(columns=[\"target\",\"idx\",\"zone_type\"], errors=\"ignore\").copy()\n",
    "num = X.select_dtypes(include=[np.number]).columns\n",
    "X[num] = X[num].fillna(0.0).astype(np.float32)\n",
    "\n",
    "yte  = D[\"target\"].astype(str).values[TE]\n",
    "zte  = D[\"zone_type\"].astype(str).values[TE]\n",
    "ite  = D[\"idx\"].astype(int).values[TE]\n",
    "\n",
    "model   = joblib.load(MODEL)\n",
    "classes = model.classes_\n",
    "Pte     = model.predict_proba(X[TE].to_numpy())\n",
    "\n",
    "with open(TH_PATH,\"r\",encoding=\"utf-8\") as f:\n",
    "    best_by_zone = json.load(f)\n",
    "\n",
    "def decide_rebound_only(P, classes, t_event, t_none, t_r, m_rb=0.0):\n",
    "    c2i = {c:i for i,c in enumerate(classes)}\n",
    "    pr, pb, pn = P[:,c2i[\"rebound\"]], P[:,c2i[\"breakout\"]], P[:,c2i[\"none\"]]\n",
    "    event_conf = np.maximum(pr, pb)\n",
    "    return np.where(\n",
    "        (event_conf >= t_event) & (pn <= t_none) & (pr >= t_r) & ((pr - pb) >= m_rb),\n",
    "        \"rebound\", \"none\"\n",
    "    )\n",
    "\n",
    "# pred binaria con whitelist + ATR filter\n",
    "atr_at_idx = df[\"ATR_14\"].loc[ite].to_numpy()\n",
    "atr_thr = np.nanquantile(df[\"ATR_14\"].values, ATR_Q)\n",
    "yhat = np.array([\"none\"]*len(ite), dtype=object)\n",
    "\n",
    "for z, conf in best_by_zone.items():\n",
    "    if z not in ZONE_WHITELIST: \n",
    "        continue\n",
    "    p = conf[\"params\"]; m = (zte == z)\n",
    "    if m.sum()==0: continue\n",
    "    yh = decide_rebound_only(Pte[m], classes, p[\"t_event\"], p[\"t_none\"], p[\"t_r\"], p[\"m_rb\"])\n",
    "    keep = atr_at_idx[m] >= atr_thr\n",
    "    yhat[m] = np.where(keep, yh, \"none\")\n",
    "\n",
    "# merge con eventos (nivel y lado) y filtra señales\n",
    "ev = pd.read_parquet(EV_PATH)[[\"idx\",\"zone_type\",\"level_price\",\"side_at_event\"]].drop_duplicates()\n",
    "test_ev = pd.DataFrame({\"idx\": ite, \"zone_type\": zte, \"yhat\": yhat}).merge(ev, on=[\"idx\",\"zone_type\"], how=\"left\")\n",
    "signals = test_ev[(test_ev[\"yhat\"]==\"rebound\") & (test_ev[\"zone_type\"].isin(ZONE_WHITELIST))].copy()\n",
    "\n",
    "# backtest\n",
    "hi = df[\"High\"].to_numpy(float); lo = df[\"Low\"].to_numpy(float); op = df[\"Open\"].to_numpy(float)\n",
    "rows=[]\n",
    "for _, r in signals.iterrows():\n",
    "    i=int(r[\"idx\"]); \n",
    "    if i+1>=len(df): continue\n",
    "    lvl=float(r[\"level_price\"]); side=str(r[\"side_at_event\"])\n",
    "    if side==\"support\":\n",
    "        tp=lvl+TP_TICKS*TICK; sl=lvl-SL_TICKS*TICK; direction=\"long\"\n",
    "    else:\n",
    "        tp=lvl-TP_TICKS*TICK; sl=lvl+SL_TICKS*TICK; direction=\"short\"\n",
    "    entry=float(op[i+1]); outcome=\"timeout\"; exit_px=float(op[min(i+H,len(df)-1)])\n",
    "    pnl=0.0\n",
    "    for j in range(i+1, min(i+H+1,len(df))):\n",
    "        if direction==\"long\":\n",
    "            if lo[j]<=sl: outcome=\"loss\";  exit_px=sl; pnl=(exit_px-entry)/TICK; break\n",
    "            if hi[j]>=tp: outcome=\"win\";   exit_px=tp; pnl=(exit_px-entry)/TICK; break\n",
    "        else:\n",
    "            if hi[j]>=sl: outcome=\"loss\";  exit_px=sl; pnl=(entry-exit_px)/TICK*(-1); break\n",
    "            if lo[j]<=tp: outcome=\"win\";   exit_px=tp; pnl=(entry-exit_px)/TICK; break\n",
    "    if outcome==\"timeout\":\n",
    "        pnl=(exit_px-entry)/TICK if direction==\"long\" else (entry-exit_px)/TICK\n",
    "    rows.append({\"idx\":i,\"zone_type\":r[\"zone_type\"],\"side\":side,\"entry\":entry,\"tp\":tp,\"sl\":sl,\"exit\":exit_px,\"outcome\":outcome,\"pnl_ticks\":pnl})\n",
    "\n",
    "bt = pd.DataFrame(rows)\n",
    "print(f\"Signals: {len(bt)} | Win%: {(bt['outcome']=='win').mean():.3f} | EV (ticks/trade): {bt['pnl_ticks'].mean():.2f}\")\n",
    "print(bt.groupby('zone_type')['pnl_ticks'].agg(['count','mean']).assign(win=lambda s: bt.groupby('zone_type')['outcome'].apply(lambda x: (x=='win').mean())).sort_values('count', ascending=False).round(3).head(10))\n",
    "\n",
    "# guarda trades y resumen\n",
    "Path(\"experiments/runs\").mkdir(parents=True, exist_ok=True)\n",
    "bt.to_csv(\"experiments/runs/rebound_v01_trades_test.csv\", index=False)\n",
    "summary = {\n",
    "    \"zones\": sorted(list(ZONE_WHITELIST)),\n",
    "    \"atr_quantile\": ATR_Q,\n",
    "    \"tp_ticks\": TP_TICKS,\n",
    "    \"sl_ticks\": SL_TICKS,\n",
    "    \"h\": H,\n",
    "    \"n_trades\": int(len(bt)),\n",
    "    \"win_rate\": float((bt['outcome']=='win').mean()),\n",
    "    \"ev_ticks\": float(bt['pnl_ticks'].mean())\n",
    "}\n",
    "import json; json.dump(summary, open(\"experiments/runs/rebound_v01_summary.json\",\"w\"), indent=2)\n",
    "print(\"Guardado: experiments/runs/rebound_v01_trades_test.csv, rebound_v01_summary.json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
