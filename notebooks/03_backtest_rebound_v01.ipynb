{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee26d234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado: c:\\Users\\jmbf2\\OneDrive\\Trading\\Machine Learning\\ZoneBasedPricePrediction\\data\\processed\\events\\events_labeled_2021_2024.plus_session.parquet\n",
      "Eventos EU+USA: (8541, 13) {'USA': 8541}\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ROOT = Path.cwd()\n",
    "for _ in range(6):\n",
    "    if (ROOT/\"data\").exists() and (ROOT/\"src\").exists(): break\n",
    "    ROOT = ROOT.parent\n",
    "\n",
    "# Carga base\n",
    "df = pd.read_parquet(ROOT/\"data/interim/ES_5m_2021_2024.parquet\")\n",
    "ev = pd.read_parquet(ROOT/\"data/processed/events/events_labeled_2021_2024.parquet\")\n",
    "\n",
    "# -- Asegurar columnas de sesión en df\n",
    "if \"session_id\" not in df.columns:\n",
    "    df[\"session_id\"] = df[\"NewSession\"].cumsum()\n",
    "if \"idx_in_session\" not in df.columns:\n",
    "    df[\"idx_in_session\"] = df.groupby(\"session_id\").cumcount()\n",
    "\n",
    "# -- Construir session_tag a partir de idx_in_session\n",
    "idx2tag = pd.Series(\"ASIA\", index=df.index)\n",
    "idx2tag.loc[df[\"idx_in_session\"].between(108,185)] = \"EU\"\n",
    "idx2tag.loc[df[\"idx_in_session\"].between(186,275)] = \"USA\"\n",
    "\n",
    "# Añadir session_tag a la tabla de eventos (por idx)\n",
    "ev[\"session_tag\"] = ev[\"idx\"].map(idx2tag)\n",
    "\n",
    "# (opcional) persiste nueva versión con session_tag\n",
    "out_ev = ROOT/\"data/processed/events/events_labeled_2021_2024.plus_session.parquet\"\n",
    "ev.to_parquet(out_ev, engine=\"pyarrow\", compression=\"zstd\", index=False)\n",
    "print(\"Guardado:\", out_ev)\n",
    "\n",
    "# Filtrado EU+USA\n",
    "ev_euusa = ev[ev[\"session_tag\"].isin([\"EU\",\"USA\"])].reset_index(drop=True)\n",
    "print(\"Eventos EU+USA:\", ev_euusa.shape, ev_euusa[\"session_tag\"].value_counts().to_dict())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e31cd93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No existe: supervised_EUUSA_EXT_k2p5.parquet -> construyendo…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jmbf2\\OneDrive\\Trading\\Machine Learning\\ZoneBasedPricePrediction\\notebooks\\../src\\ppz\\features\\of_imbalance.py:46: RuntimeWarning: All-NaN slice encountered\n",
      "  (np.nanmax(buy_ratio)  >= k_ext) if np.isfinite(np.nanmax(buy_ratio))  else False\n",
      "c:\\Users\\jmbf2\\OneDrive\\Trading\\Machine Learning\\ZoneBasedPricePrediction\\notebooks\\../src\\ppz\\features\\of_imbalance.py:48: RuntimeWarning: All-NaN slice encountered\n",
      "  (np.nanmax(sell_ratio) >= k_ext) if np.isfinite(np.nanmax(sell_ratio)) else False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Construido y guardado: c:\\Users\\jmbf2\\OneDrive\\Trading\\Machine Learning\\ZoneBasedPricePrediction\\data\\processed\\features\\supervised_EUUSA_EXT_k2p5.parquet | shape: (8541, 33)\n",
      "AP_macro: 0.3599 | AP: {'breakout': 0.3299, 'none': 0.265, 'rebound': 0.4847} | Brier: 0.21406\n",
      "Guardado artefactos en: c:\\Users\\jmbf2\\OneDrive\\Trading\\Machine Learning\\ZoneBasedPricePrediction\\models\\artifacts\n"
     ]
    }
   ],
   "source": [
    "# --- B) Entrenar + calibrar (auto-build si falta el parquet) ---\n",
    "import numpy as np, pandas as pd, joblib, json\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.metrics import average_precision_score, brier_score_loss\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from importlib import reload\n",
    "\n",
    "# localizar raíz del repo\n",
    "ROOT = Path.cwd()\n",
    "for _ in range(6):\n",
    "    if (ROOT/\"data\").exists() and (ROOT/\"src\").exists(): break\n",
    "    ROOT = ROOT.parent\n",
    "\n",
    "DF_PATH = ROOT/\"data/interim/ES_5m_2021_2024.parquet\"\n",
    "EV_PATH = ROOT/\"data/processed/events/events_labeled_2021_2024.parquet\"\n",
    "PQ      = ROOT/\"data/processed/features/supervised_EUUSA_EXT_k2p5.parquet\"\n",
    "\n",
    "# --- helper: asegurar ev_euusa (construye session_tag si no existe) ---\n",
    "def load_ev_euusa():\n",
    "    df = pd.read_parquet(DF_PATH)\n",
    "    ev = pd.read_parquet(EV_PATH)\n",
    "\n",
    "    if \"session_id\" not in df.columns:\n",
    "        df[\"session_id\"] = df[\"NewSession\"].cumsum()\n",
    "    if \"idx_in_session\" not in df.columns:\n",
    "        df[\"idx_in_session\"] = df.groupby(\"session_id\").cumcount()\n",
    "\n",
    "    # mapa idx -> tag por intradía\n",
    "    idx2tag = pd.Series(\"ASIA\", index=df.index)\n",
    "    idx2tag.loc[df[\"idx_in_session\"].between(108,185)] = \"EU\"\n",
    "    idx2tag.loc[df[\"idx_in_session\"].between(186,275)] = \"USA\"\n",
    "\n",
    "    if \"session_tag\" not in ev.columns:\n",
    "        ev[\"session_tag\"] = ev[\"idx\"].map(idx2tag)\n",
    "\n",
    "    ev_euusa = ev[ev[\"session_tag\"].isin([\"EU\",\"USA\"])].reset_index(drop=True)\n",
    "    return df, ev_euusa\n",
    "\n",
    "# --- helper: construir dataset EXT k=2.5 si falta ---\n",
    "def build_ext_k25():\n",
    "    from ppz.pipelines.build_dataset import make_supervised_from_events\n",
    "    df, ev_euusa = load_ev_euusa()\n",
    "\n",
    "    X_ext, y_ext = make_supervised_from_events(\n",
    "        df, ev_euusa,\n",
    "        tick_size=0.25, n_short=20, n_long=60,\n",
    "        L_prev_touches=60, r_touch_ticks=6, drop_none=False,\n",
    "        add_mvc=True, add_orderflow=True, of_k=2.5, of_k_ext=4.5\n",
    "    )\n",
    "    num = X_ext.select_dtypes(include=\"number\").columns\n",
    "    X_ext[num] = X_ext[num].fillna(0.0).astype(\"float32\")\n",
    "    Xe = X_ext.copy(); Xe[\"target\"] = y_ext.values\n",
    "    PQ.parent.mkdir(parents=True, exist_ok=True)\n",
    "    Xe.to_parquet(PQ, engine=\"pyarrow\", compression=\"zstd\", index=False)\n",
    "    print(\"Construido y guardado:\", PQ, \"| shape:\", Xe.shape)\n",
    "\n",
    "# --- carga (o construcción) del parquet ---\n",
    "if not PQ.exists():\n",
    "    print(\"No existe:\", PQ.name, \"-> construyendo…\")\n",
    "    build_ext_k25()\n",
    "\n",
    "# --- entrenamiento + calibración ---\n",
    "D  = pd.read_parquet(PQ)\n",
    "df = pd.read_parquet(DF_PATH)\n",
    "\n",
    "t   = df[\"Time\"].dt.tz_convert(\"Europe/Madrid\")\n",
    "idx = D[\"idx\"].astype(int)\n",
    "TR  = (t.loc[idx] < \"2024-01-01\").values\n",
    "VA  = (t.loc[idx] >= \"2024-01-01\").values & (t.loc[idx] < \"2024-07-01\").values\n",
    "TE  = (t.loc[idx] >= \"2024-07-01\").values\n",
    "\n",
    "X = D.drop(columns=[\"target\",\"idx\",\"zone_type\"], errors=\"ignore\").copy()\n",
    "num = X.select_dtypes(include=\"number\").columns\n",
    "X[num] = X[num].fillna(0.0).astype(\"float32\")\n",
    "y = D[\"target\"].astype(str).values\n",
    "classes = sorted(np.unique(y).tolist())\n",
    "\n",
    "hgb = HistGradientBoostingClassifier(\n",
    "    learning_rate=0.06, max_leaf_nodes=25, min_samples_leaf=160, l2_regularization=0.25,\n",
    "    random_state=42\n",
    ").fit(X[TR].to_numpy(), y[TR])\n",
    "\n",
    "# isotónica OvR en VALID\n",
    "P_va = np.column_stack([hgb.predict_proba(X[VA].to_numpy())[:, list(hgb.classes_).index(c)] for c in classes])\n",
    "Y_va_bin = label_binarize(y[VA], classes=classes)\n",
    "isos, P_va_cal = {}, np.zeros_like(P_va)\n",
    "for k,c in enumerate(classes):\n",
    "    ir = IsotonicRegression(out_of_bounds=\"clip\").fit(P_va[:,k], Y_va_bin[:,k])\n",
    "    isos[c] = ir; P_va_cal[:,k] = ir.transform(P_va[:,k])\n",
    "\n",
    "def predict_proba_cal(Xm):\n",
    "    P = np.column_stack([hgb.predict_proba(Xm)[:, list(hgb.classes_).index(c)] for c in classes])\n",
    "    Pcal = np.column_stack([isos[c].transform(P[:,k]) for k,c in enumerate(classes)])\n",
    "    s = Pcal.sum(axis=1, keepdims=True); s[s==0]=1.0\n",
    "    return Pcal/s\n",
    "\n",
    "P_te = predict_proba_cal(X[TE].to_numpy()); y_te = y[TE]\n",
    "ap_macro = average_precision_score(label_binarize(y_te, classes=classes), P_te, average=\"macro\")\n",
    "brier    = np.mean([brier_score_loss((y_te==c).astype(int), P_te[:,i]) for i,c in enumerate(classes)])\n",
    "ap_pc    = {c: average_precision_score((y_te==c).astype(int), P_te[:,i]) for i,c in enumerate(classes)}\n",
    "print(\"AP_macro:\", round(ap_macro,4), \"| AP:\", {k:round(v,4) for k,v in ap_pc.items()}, \"| Brier:\", round(brier,5))\n",
    "\n",
    "ART = ROOT/\"models/artifacts\"; ART.mkdir(parents=True, exist_ok=True)\n",
    "art_path = ART/\"HGB_EUUSA_EXTk2p5_calibrated_isotonic.joblib\"\n",
    "joblib.dump({\"model\":hgb,\"classes\":classes,\"isos\":isos}, art_path)\n",
    "json.dump({\n",
    "    \"name\":\"HGB_EUUSA_EXTk2p5\", \"ap_macro_test\": float(ap_macro),\n",
    "    \"ap_per_class_test\": {k: float(v) for k,v in ap_pc.items()},\n",
    "    \"brier_test\": float(brier), \"n_features\": int(X.shape[1]),\n",
    "}, open(ART/\"HGB_EUUSA_EXTk2p5_report_test.json\",\"w\"), indent=2)\n",
    "print(\"Guardado artefactos en:\", ART)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12e70c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado: c:\\Users\\jmbf2\\OneDrive\\Trading\\Machine Learning\\ZoneBasedPricePrediction\\models\\artifacts\\rebound_thresholds_by_zone_k2p5.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'USA_IBH': {'f1_macro_val': 0.4813475993615316,\n",
       "  'params': {'t_event': 0.55, 't_none': 0.5, 't_r': 0.575, 'm_rb': 0.0}},\n",
       " 'USA_IBL': {'f1_macro_val': 0.36296039090058924,\n",
       "  'params': {'t_event': 0.55, 't_none': 0.5, 't_r': 0.6, 'm_rb': 0.0}},\n",
       " 'VWAP': {'f1_macro_val': 0.3197979795746071,\n",
       "  'params': {'t_event': 0.55, 't_none': 0.5, 't_r': 0.575, 'm_rb': 0.0}},\n",
       " 'PDL_prev': {'f1_macro_val': 0.3203124997772827,\n",
       "  'params': {'t_event': 0.55, 't_none': 0.5, 't_r': 0.575, 'm_rb': 0.0}},\n",
       " 'VAL_D1': {'f1_macro_val': 0.37179487155654173,\n",
       "  'params': {'t_event': 0.55, 't_none': 0.5, 't_r': 0.575, 'm_rb': 0.0}},\n",
       " 'POC_D1': {'f1_macro_val': 0.3676676262020822,\n",
       "  'params': {'t_event': 0.55, 't_none': 0.5, 't_r': 0.575, 'm_rb': 0.0}},\n",
       " 'VAH_D1': {'f1_macro_val': 0.380566801351401,\n",
       "  'params': {'t_event': 0.55, 't_none': 0.5, 't_r': 0.575, 'm_rb': 0.0}},\n",
       " 'PDH_prev': {'f1_macro_val': 0.4146126757054678,\n",
       "  'params': {'t_event': 0.55, 't_none': 0.5, 't_r': 0.575, 'm_rb': 0.0}}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- C) Re-tuning de umbrales por zona (VALIDACIÓN) ---\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd, json, joblib\n",
    "\n",
    "# localizar raíz del repo\n",
    "ROOT = Path.cwd()\n",
    "for _ in range(6):\n",
    "    if (ROOT/\"data\").exists() and (ROOT/\"src\").exists():\n",
    "        break\n",
    "    ROOT = ROOT.parent\n",
    "\n",
    "PQ       = ROOT/\"data/processed/features/supervised_EUUSA_EXT_k2p5.parquet\"\n",
    "ART      = ROOT/\"models/artifacts/HGB_EUUSA_EXTk2p5_calibrated_isotonic.joblib\"\n",
    "DF_PATH  = ROOT/\"data/interim/ES_5m_2021_2024.parquet\"\n",
    "EV_PATH  = ROOT/\"data/processed/events/events_labeled_2021_2024.parquet\"\n",
    "OUTJSON  = ROOT/\"models/artifacts/rebound_thresholds_by_zone_k2p5.json\"\n",
    "\n",
    "# carga datasets\n",
    "D  = pd.read_parquet(PQ)\n",
    "df = pd.read_parquet(DF_PATH)\n",
    "\n",
    "# asegurar zone_type (join por idx si faltara)\n",
    "if \"zone_type\" not in D.columns:\n",
    "    ev = pd.read_parquet(EV_PATH)[[\"idx\",\"zone_type\"]]\n",
    "    D = D.merge(ev, on=\"idx\", how=\"left\")\n",
    "\n",
    "# split VALID por tiempo\n",
    "t   = df[\"Time\"].dt.tz_convert(\"Europe/Madrid\")\n",
    "idx = D[\"idx\"].astype(int).values\n",
    "VA_mask = ((t.loc[idx] >= \"2024-01-01\") & (t.loc[idx] < \"2024-07-01\")).to_numpy()\n",
    "\n",
    "# X (solo numéricas, float32), y, zonas\n",
    "Xva = D.drop(columns=[\"target\",\"idx\",\"zone_type\"], errors=\"ignore\").copy()\n",
    "num_cols = Xva.select_dtypes(include=[np.number]).columns\n",
    "Xva[num_cols] = Xva[num_cols].fillna(0.0).astype(\"float32\")\n",
    "Xva = Xva.iloc[VA_mask]\n",
    "\n",
    "yva = D[\"target\"].astype(str).values[VA_mask]\n",
    "zva = D[\"zone_type\"].astype(str).values[VA_mask]\n",
    "\n",
    "# cargar modelo calibrado\n",
    "art = joblib.load(ART)\n",
    "model, classes, isos = art[\"model\"], art[\"classes\"], art[\"isos\"]\n",
    "c2i = {c:i for i,c in enumerate(classes)}\n",
    "\n",
    "def proba_cal(X):\n",
    "    P = np.column_stack([model.predict_proba(X)[:, c2i[c]] for c in classes])\n",
    "    Pcal = np.column_stack([isos[c].transform(P[:,i]) for i,c in enumerate(classes)])\n",
    "    s = Pcal.sum(axis=1, keepdims=True); s[s==0]=1.0\n",
    "    return Pcal/s\n",
    "\n",
    "Pva = proba_cal(Xva.to_numpy())\n",
    "pr, pb, pn = Pva[:,c2i[\"rebound\"]], Pva[:,c2i[\"breakout\"]], Pva[:,c2i[\"none\"]]\n",
    "\n",
    "def f1_macro_bin(y_true, y_hat):\n",
    "    yb = np.where(y_true==\"rebound\",\"rebound\",\"none\")\n",
    "    tp   = np.sum((y_hat==\"rebound\") & (yb==\"rebound\"))\n",
    "    fp   = np.sum((y_hat==\"rebound\") & (yb==\"none\"))\n",
    "    fn   = np.sum((y_hat==\"none\")    & (yb==\"rebound\"))\n",
    "    prec = tp/(tp+fp+1e-9); rec = tp/(tp+fn+1e-9)\n",
    "    f1_r = 2*prec*rec/(prec+rec+1e-9)\n",
    "    tp_n = np.sum((y_hat==\"none\") & (yb==\"none\"))\n",
    "    fp_n = np.sum((y_hat==\"none\") & (yb==\"rebound\"))\n",
    "    fn_n = np.sum((y_hat==\"rebound\") & (yb==\"none\"))\n",
    "    prec_n = tp_n/(tp_n+fp_n+1e-9); rec_n = tp_n/(tp_n+fn_n+1e-9)\n",
    "    f1_n = 2*prec_n*rec_n/(prec_n+rec_n+1e-9)\n",
    "    return 0.5*(f1_r+f1_n)\n",
    "\n",
    "def search_zone(mask):\n",
    "    best_score, best_params = -1.0, None\n",
    "    econf = np.maximum(pr[mask], pb[mask])  # “hay evento”\n",
    "    for t_event in (0.55, 0.60, 0.65):\n",
    "        for t_none in (0.50, 0.55, 0.60):\n",
    "            for t_r in (0.575, 0.60, 0.625):\n",
    "                for m_rb in (0.0, 0.05, 0.10):\n",
    "                    y_hat = np.where(\n",
    "                        (econf>=t_event) & (pn[mask]<=t_none) &\n",
    "                        (pr[mask]>=t_r) & ((pr[mask]-pb[mask])>=m_rb),\n",
    "                        \"rebound\",\"none\"\n",
    "                    )\n",
    "                    score = f1_macro_bin(yva[mask], y_hat)\n",
    "                    if score > best_score:\n",
    "                        best_score = score\n",
    "                        best_params = dict(t_event=t_event, t_none=t_none, t_r=t_r, m_rb=m_rb)\n",
    "    return best_score, best_params\n",
    "\n",
    "best_by_zone = {}\n",
    "for z in pd.Series(zva).unique():\n",
    "    m = (zva==z)\n",
    "    if m.sum() < 80:   # evita sobreajuste con muy pocos ejemplos\n",
    "        continue\n",
    "    score, params = search_zone(m)\n",
    "    best_by_zone[z] = {\"f1_macro_val\": float(score), \"params\": params}\n",
    "\n",
    "OUTJSON.parent.mkdir(parents=True, exist_ok=True)\n",
    "with open(OUTJSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(best_by_zone, f, indent=2)\n",
    "\n",
    "print(\"Guardado:\", OUTJSON)\n",
    "best_by_zone\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d12a84eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zone_type</th>\n",
       "      <th>support</th>\n",
       "      <th>precision_rebound</th>\n",
       "      <th>recall_rebound</th>\n",
       "      <th>precision_none</th>\n",
       "      <th>recall_none</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PDH_prev</td>\n",
       "      <td>118</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PDL_prev</td>\n",
       "      <td>58</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.534</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POC_D1</td>\n",
       "      <td>123</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USA_IBH</td>\n",
       "      <td>181</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USA_IBL</td>\n",
       "      <td>153</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.449</td>\n",
       "      <td>0.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>VAH_D1</td>\n",
       "      <td>111</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VAL_D1</td>\n",
       "      <td>83</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>VWAP</td>\n",
       "      <td>201</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  zone_type  support  precision_rebound  recall_rebound  precision_none  \\\n",
       "0  PDH_prev      118              0.167           0.020           0.562   \n",
       "1  PDL_prev       58              0.000           0.000           0.534   \n",
       "2    POC_D1      123              0.400           0.034           0.517   \n",
       "3   USA_IBH      181              0.519           0.152           0.494   \n",
       "4   USA_IBL      153              0.167           0.012           0.449   \n",
       "5    VAH_D1      111              0.400           0.040           0.547   \n",
       "6    VAL_D1       83              0.333           0.029           0.575   \n",
       "7      VWAP      201              0.000           0.000           0.508   \n",
       "\n",
       "   recall_none  \n",
       "0        0.926  \n",
       "1        1.000  \n",
       "2        0.953  \n",
       "3        0.854  \n",
       "4        0.930  \n",
       "5        0.951  \n",
       "6        0.958  \n",
       "7        0.981  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np, pandas as pd, json, joblib\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# --- rutas robustas ---\n",
    "ROOT = Path.cwd()\n",
    "for _ in range(6):\n",
    "    if (ROOT/\"data\").exists() and (ROOT/\"src\").exists(): break\n",
    "    ROOT = ROOT.parent\n",
    "\n",
    "PQ      = ROOT/\"data/processed/features/supervised_EUUSA_EXT_k2p5.parquet\"\n",
    "DF_PATH = ROOT/\"data/interim/ES_5m_2021_2024.parquet\"\n",
    "ART     = ROOT/\"models/artifacts/HGB_EUUSA_EXTk2p5_calibrated_isotonic.joblib\"\n",
    "TH_PATH = ROOT/\"models/artifacts/rebound_thresholds_by_zone_k2p5.json\"\n",
    "EV_PATH = ROOT/\"data/processed/events/events_labeled_2021_2024.parquet\"\n",
    "\n",
    "# --- carga datos y modelo ---\n",
    "D  = pd.read_parquet(PQ)\n",
    "df = pd.read_parquet(DF_PATH)\n",
    "art = joblib.load(ART)\n",
    "model, classes, isos = art[\"model\"], art[\"classes\"], art[\"isos\"]\n",
    "c2i = {c:i for i,c in enumerate(classes)}\n",
    "\n",
    "# asegurar zone_type (si no via join con events)\n",
    "if \"zone_type\" not in D.columns:\n",
    "    ev = pd.read_parquet(EV_PATH)[[\"idx\",\"zone_type\"]]\n",
    "    D = D.merge(ev, on=\"idx\", how=\"left\")\n",
    "\n",
    "# split TEST (2024H2)\n",
    "t   = df[\"Time\"].dt.tz_convert(\"Europe/Madrid\")\n",
    "idx = D[\"idx\"].astype(int).values\n",
    "TE_mask = (t.loc[idx] >= \"2024-07-01\").to_numpy()\n",
    "\n",
    "X = D.drop(columns=[\"target\",\"idx\",\"zone_type\"], errors=\"ignore\").copy()\n",
    "num = X.select_dtypes(include=[np.number]).columns\n",
    "X[num] = X[num].fillna(0.0).astype(\"float32\")\n",
    "Xte = X.iloc[TE_mask].to_numpy()\n",
    "\n",
    "y_true_full = D[\"target\"].astype(str).values[TE_mask]\n",
    "z_full      = D[\"zone_type\"].astype(str).values[TE_mask]\n",
    "\n",
    "# proba calibrada\n",
    "def proba_cal(Xm):\n",
    "    P = np.column_stack([model.predict_proba(Xm)[:, c2i[c]] for c in classes])\n",
    "    Pcal = np.column_stack([isos[c].transform(P[:,i]) for i,c in enumerate(classes)])\n",
    "    s = Pcal.sum(axis=1, keepdims=True); s[s==0]=1.0\n",
    "    return Pcal/s\n",
    "\n",
    "Pte = proba_cal(Xte)\n",
    "pr, pb, pn = Pte[:,c2i[\"rebound\"]], Pte[:,c2i[\"breakout\"]], Pte[:,c2i[\"none\"]]\n",
    "event_conf = np.maximum(pr, pb)\n",
    "\n",
    "# umbrales por zona\n",
    "thr = json.load(open(TH_PATH,\"r\"))\n",
    "\n",
    "rows = []\n",
    "for z in sorted(pd.Series(z_full).dropna().unique()):\n",
    "    if z not in thr: \n",
    "        continue\n",
    "    p = thr[z][\"params\"]\n",
    "    m = (z_full == z)\n",
    "    if m.sum() < 30:\n",
    "        continue\n",
    "\n",
    "    # decisiones (binario rebound/none)\n",
    "    y_hat = np.where(\n",
    "        (event_conf[m] >= p[\"t_event\"]) &\n",
    "        (pn[m] <= p[\"t_none\"]) &\n",
    "        (pr[m] >= p[\"t_r\"]) &\n",
    "        ((pr[m] - pb[m]) >= p[\"m_rb\"]),\n",
    "        \"rebound\", \"none\"\n",
    "    )\n",
    "    y_bin_true = (y_true_full[m] == \"rebound\").astype(int)\n",
    "    y_bin_hat  = (y_hat == \"rebound\").astype(int)\n",
    "\n",
    "    prec_r = precision_score(y_bin_true, y_bin_hat, zero_division=0)\n",
    "    rec_r  = recall_score(y_bin_true, y_bin_hat, zero_division=0)\n",
    "\n",
    "    # métricas para clase none (invirtiendo etiquetas)\n",
    "    yb_true_n = 1 - y_bin_true\n",
    "    yb_hat_n  = 1 - y_bin_hat\n",
    "    prec_n = precision_score(yb_true_n, yb_hat_n, zero_division=0)\n",
    "    rec_n  = recall_score(yb_true_n, yb_hat_n, zero_division=0)\n",
    "\n",
    "    rows.append({\n",
    "        \"zone_type\": z,\n",
    "        \"support\": int(m.sum()),\n",
    "        \"precision_rebound\": round(prec_r,3),\n",
    "        \"recall_rebound\": round(rec_r,3),\n",
    "        \"precision_none\": round(prec_n,3),\n",
    "        \"recall_none\": round(rec_n,3),\n",
    "    })\n",
    "\n",
    "tabla = pd.DataFrame(rows).sort_values(\"zone_type\").reset_index(drop=True)\n",
    "tabla\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
